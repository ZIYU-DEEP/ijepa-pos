
INFO:root:/ibex/user/linj0b/logs/ijepa-pos/vit_small/ijepa/bs256_lr_0.001_ep300_ps_14_pr0_pl0.2_sl0.0002_fl1e-06_fw0.4_wp40_wd0.04_de256_dh8_dd2_ucFalse_ugFalse_uhFalse
INFO:root:VisionTransformer(
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
  (avg_pool): FeatAvgPool(
    (avg_pool): AdaptiveAvgPool1d(output_size=1)
  )
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))
  )
  (decoder_embed): Linear(in_features=384, out_features=256, bias=True)
  (decoder_blocks): ModuleList(
    (0-1): 2 x Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (decoder_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=256, out_features=256, bias=True)
  (prober): Linear(in_features=384, out_features=100, bias=True)
)
INFO:root:making imagenet data transforms
INFO:root:data-path /ibex/user/linj0b/data/imagenet_100/train/
INFO:root:Initialized ImageNet
INFO:root:ImageNet dataset created
INFO:root:ImageNet unsupervised data loader created
INFO:root:Using AdamW
INFO:root:Epoch 1
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x1482ac003e20>
Traceback (most recent call last):
  File "/ibex/user/linj0b/anaconda3/envs/jepa/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
    self._shutdown_workers()
  File "/ibex/user/linj0b/anaconda3/envs/jepa/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1442, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/ibex/user/linj0b/anaconda3/envs/jepa/lib/python3.10/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/ibex/user/linj0b/anaconda3/envs/jepa/lib/python3.10/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
  File "/ibex/user/linj0b/anaconda3/envs/jepa/lib/python3.10/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ibex/user/linj0b/anaconda3/envs/jepa/lib/python3.10/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ibex/user/linj0b/anaconda3/envs/jepa/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1081111) is killed by signal: Aborted.
Process Process-1:
Traceback (most recent call last):
  File "/ibex/user/linj0b/anaconda3/envs/jepa/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/ibex/user/linj0b/anaconda3/envs/jepa/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/ibex/user/linj0b/github/ijepa-pos/main_pos.py", line 66, in process_main
    app_main(args=params, port=port)
  File "/ibex/user/linj0b/github/ijepa-pos/src/train_pos.py", line 493, in main
    (loss, ijepa_loss, pos_loss, _new_lr, probe_loss, probe_acc, _new_wd, grad_stats), etime = gpu_timer(train_step)
  File "/ibex/user/linj0b/github/ijepa-pos/src/utils/logging.py", line 21, in gpu_timer
    result = closure()
  File "/ibex/user/linj0b/github/ijepa-pos/src/train_pos.py", line 438, in train_step
    with torch.cuda.amp.autocast(dtype=torch.bfloat16, enabled=use_bfloat16):
  File "/ibex/user/linj0b/anaconda3/envs/jepa/lib/python3.10/site-packages/torch/cuda/amp/autocast_mode.py", line 34, in __init__
    super().__init__(
  File "/ibex/user/linj0b/anaconda3/envs/jepa/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 305, in __init__
    raise RuntimeError(
RuntimeError: Current CUDA Device does not support bfloat16. Please switch dtype to float16.